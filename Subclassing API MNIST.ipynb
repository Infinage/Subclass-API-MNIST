{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The project:\n",
    "\n",
    "MNIST Classifier from scratch, without using the inbuilt layers, activations, losses, etc using the subclassing API with a custom loop.\n",
    "\n",
    "Before which let's first create a MNIST classifier with all these:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train,), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# scale the values to be within [0, 1]\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test /  255.0\n",
    "\n",
    "# printing out the shapes\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create the model using the functional API:\n",
    "We are trying to implement a 'Deep and Wide' neural network to add complexity for our custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Deep_N_Wide_Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 784)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          100480      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           2570        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 185,354\n",
      "Trainable params: 185,354\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating the input layer\n",
    "inp = tf.keras.layers.Input(shape=(28, 28))\n",
    "# flatten the inputs \n",
    "flatten = tf.keras.layers.Flatten()(inp)\n",
    "\n",
    "# dense layer blocks\n",
    "dense1 = tf.keras.layers.Dense(units=128, activation='elu', kernel_initializer='he_normal')(flatten)\n",
    "dense2 = tf.keras.layers.Dense(units=128, activation='elu', kernel_initializer='he_normal')(dense1)\n",
    "\n",
    "# we concatenate two consequtive layers and feed it to a drop out layer\n",
    "conc = tf.keras.layers.Concatenate()([dense1, dense2])\n",
    "\n",
    "# drop out layer\n",
    "dropout1 = tf.keras.layers.Dropout(0.2)(conc)\n",
    "\n",
    "# final dense which then feeds to the output layer which does predictions\n",
    "dense3  = tf.keras.layers.Dense(units=256, activation='elu', kernel_initializer='he_normal')(dropout1)\n",
    "\n",
    "# the output layer making predictions\n",
    "op = tf.keras.layers.Dense(10, activation='softmax')(dense3)\n",
    "\n",
    "# create the functional api model\n",
    "model = tf.keras.models.Model(name='Deep_N_Wide_Model', inputs=[inp], outputs=[op])\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             metrics=tf.keras.metrics.SparseCategoricalAccuracy(name='SCAcc'))\n",
    "\n",
    "# let's print out the summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps an visual flowchart might help us better see the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2538 - SCAcc: 0.9224 - val_loss: 0.1500 - val_SCAcc: 0.9520 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1277 - SCAcc: 0.9599 - val_loss: 0.1176 - val_SCAcc: 0.9624 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0984 - SCAcc: 0.9688 - val_loss: 0.1117 - val_SCAcc: 0.9683 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0814 - SCAcc: 0.9753 - val_loss: 0.0921 - val_SCAcc: 0.9708 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 0.0367 - SCAcc: 0.9877 - val_loss: 0.0605 - val_SCAcc: 0.9826 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0275 - SCAcc: 0.9915 - val_loss: 0.0569 - val_SCAcc: 0.9829 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0247 - SCAcc: 0.9919 - val_loss: 0.0564 - val_SCAcc: 0.9836 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0194 - SCAcc: 0.9941 - val_loss: 0.0560 - val_SCAcc: 0.9839 - lr: 1.0000e-05\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0185 - SCAcc: 0.9943 - val_loss: 0.0562 - val_SCAcc: 0.9838 - lr: 1.0000e-05\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0183 - SCAcc: 0.9945 - val_loss: 0.0559 - val_SCAcc: 0.9837 - lr: 1.0000e-05\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0173 - SCAcc: 0.9948 - val_loss: 0.0559 - val_SCAcc: 0.9837 - lr: 1.0000e-06\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0179 - SCAcc: 0.9945 - val_loss: 0.0558 - val_SCAcc: 0.9836 - lr: 1.0000e-06\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0178 - SCAcc: 0.9946 - val_loss: 0.0558 - val_SCAcc: 0.9838 - lr: 1.0000e-06\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0173 - SCAcc: 0.9947 - val_loss: 0.0558 - val_SCAcc: 0.9837 - lr: 1.0000e-07\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0181 - SCAcc: 0.9945 - val_loss: 0.0558 - val_SCAcc: 0.9838 - lr: 1.0000e-07\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0175 - SCAcc: 0.9944 - val_loss: 0.0558 - val_SCAcc: 0.9838 - lr: 1.0000e-07\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0173 - SCAcc: 0.9949 - val_loss: 0.0558 - val_SCAcc: 0.9838 - lr: 1.0000e-08\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0171 - SCAcc: 0.9946 - val_loss: 0.0558 - val_SCAcc: 0.9838 - lr: 1.0000e-08\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0174 - SCAcc: 0.9947 - val_loss: 0.0558 - val_SCAcc: 0.9838 - lr: 1.0000e-08\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0179 - SCAcc: 0.9942 - val_loss: 0.0558 - val_SCAcc: 0.9838 - lr: 1.0000e-09\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualise the models training performance\n",
    "pd.DataFrame(hist.history).plot(figsize=(10, 10), ylim=[0, 1], xlim=[0, 20], title='Epoch vs Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's create the model we created above from scratch using subclassing API:\n",
    "\n",
    "#### Loss functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_cross_entropy(tf.keras.losses.Loss):\n",
    "    '''Cross entropy loss, loss layers inherit from keras.losses.loss class.\n",
    "    Requires one hot encoded targets'''\n",
    "    \n",
    "    def __init__(self, epsilon=1e-12, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        pred = tf.clip_by_value(y_pred, self.epsilon, 1.0 - self.epsilon)\n",
    "        N = pred.shape[0]\n",
    "        ce = -tf.reduce_sum(tf.math.log(pred) * y_true) / N\n",
    "        \n",
    "        return ce\n",
    "        \n",
    "    def get_config(self):\n",
    "        # this is a must if we hope to save our model someday\n",
    "        return {**super().get_config(), \"epsilon\": self.epsilon}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_s_cross_entropy(tf.keras.losses.Loss):\n",
    "    '''Same as above but sparse_crossentropy loss.\n",
    "    Takes in sparse targets.'''\n",
    "    \n",
    "    def __init__(self, epsilon=1e-12, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        \n",
    "        # one hot encode the targets and squeeze any dimensions of value 1\n",
    "        y_true = tf.squeeze(tf.one_hot(y_true, depth=y_pred.shape[-1]))\n",
    "        \n",
    "        # exactly copied from above loss snippet\n",
    "        pred = tf.clip_by_value(y_pred, self.epsilon, 1.0 - self.epsilon)\n",
    "        N = pred.shape[0]\n",
    "        \n",
    "        # we add the epsilon value since the model loss \n",
    "        # hits NAN when trained for longer periods\n",
    "        ce = -tf.reduce_sum(tf.math.log(pred + 1e-9) * y_true) / N\n",
    "        \n",
    "        return ce\n",
    "        \n",
    "    def get_config(self):\n",
    "        return {**super().get_config(), \"epsilon\": self.epsilon}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume to be the model's predictions\n",
    "predictions = np.array([[0.05 , 0.95, 0],\n",
    "                        [0.1, 0.8, 0.1]], dtype=np.float32)\n",
    "\n",
    "# sparse targets (actual)\n",
    "s_targets = np.array([[1], [2]], dtype=np.float32)\n",
    "\n",
    "# one hot encoded targets (actual)\n",
    "targets = np.array([[0., 1., 0.], [0., 0., 1.]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare the outputs of keras implementation with ours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Output: 1.1769392\n",
      "Our Output: 1.1769392\n"
     ]
    }
   ],
   "source": [
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "print (\"Keras Output:\", cce(targets, predictions).numpy())\n",
    "print (\"Our Output:\", my_cross_entropy()(targets, predictions).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Output: 1.1769392\n",
      "Our Output: 1.1769392\n"
     ]
    }
   ],
   "source": [
    "sce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "print (\"Keras Output:\", sce(s_targets, predictions).numpy())\n",
    "print (\"Our Output:\", my_s_cross_entropy()(s_targets, predictions).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working good, let's move on to create the SparseCategoricalAccuracy Metric\n",
    "\n",
    "### Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_scacc_metric(tf.keras.metrics.Metric):\n",
    "    '''Creating a stateful metric, which keeps updating itself with streaming scores.\n",
    "    No args to init, hence get_config is not needed.'''\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        # intialize total & count to calculate the mean when required\n",
    "        self.total = self.add_weight(\"total\", initializer='zeros')\n",
    "        self.count = self.add_weight(\"count\", initializer='zeros')\n",
    "        \n",
    "        # creating the metric from function we have already defined, redundant\n",
    "        self.calc_acc = my_scacc_metric.my_SCAcc\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weights=None):\n",
    "        '''Gets called inside the loop for every step of the epoch'''\n",
    "        \n",
    "        metrics = self.calc_acc(y_true, y_pred)\n",
    "        \n",
    "        # update the total scores along with count for later purpose\n",
    "        self.total.assign_add(tf.reduce_sum(metrics))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), dtype=tf.float32))\n",
    "    \n",
    "    def my_SCAcc(y_true, y_pred):\n",
    "        scores = tf.cast(tf.equal(\n",
    "            tf.cast(tf.reduce_max(y_true, axis=-1), dtype=tf.float32), \n",
    "            tf.cast(tf.argmax(y_pred, axis=-1), dtype=tf.float32),\n",
    "        ), dtype=tf.float32)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def result(self):\n",
    "        '''Gets called at the end of epoch. Calculate the mean'''\n",
    "        return self.total / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = [[2], [1]]\n",
    "predictions = [[0.1, 0.9, 0.8], [0.05, 0.95, 0]]\n",
    "temp = my_scacc_metric()\n",
    "temp.update_state(targets, predictions)\n",
    "temp.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activations:\n",
    "Metrics is working fine, let's move on to creating our own activations for `Softmax` & `elu`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_elu(tf.keras.layers.Layer):\n",
    "    def __init__(self, alpha=1., **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def call(self, z):\n",
    "        \n",
    "        z = tf.cast(z, dtype=tf.float32)\n",
    "        return tf.where(z > 0, z, self.alpha * (tf.exp(z) - 1))\n",
    "            \n",
    "    def get_config(self):\n",
    "        return {**super().get_config(), \"alpha\": self.alpha}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.63212055, -0.9998766 , 10.        , 20.        ], dtype=float32)>"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_elu()(tf.constant([-1, -9, 10, 20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.shape(tf.constant([[1, 2, 3], [2, 3, 4]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax(z, axis=-1):    \n",
    "    ndim = len(tf.shape(z))\n",
    "    if ndim == 2:\n",
    "        return tf.nn.softmax(z)\n",
    "    elif ndim > 2:\n",
    "        e = tf.exp(z - tf.reduce_max(z, axis=axis, keepdims=True))\n",
    "        s = tf.reduce_sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D. '\n",
    "                         'Received input: %s' % z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.09003057, 0.24472848, 0.66524094]], dtype=float32)>"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_softmax(tf.constant([[1., 2., 3.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializers:\n",
    "Let's now move on to create the golorot normal and he_normal intializers for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_glorot_init(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[ 0.6974226 ],\n",
       "       [-0.35105956],\n",
       "       [-0.2997724 ],\n",
       "       [ 0.1749831 ],\n",
       "       [ 0.46001196],\n",
       "       [ 0.44626623],\n",
       "       [-0.27885336],\n",
       "       [-0.31279862],\n",
       "       [-0.44361517],\n",
       "       [ 0.8710123 ]], dtype=float32)>"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_glorot_init([10,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_he_init(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / shape[0])\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[-0.05962639],\n",
       "       [ 0.24382487],\n",
       "       [ 0.47306964],\n",
       "       [ 0.37291068],\n",
       "       [-0.6868492 ],\n",
       "       [ 0.17765294],\n",
       "       [-0.07778834],\n",
       "       [ 0.29282498],\n",
       "       [-1.0894686 ],\n",
       "       [-0.31218007]], dtype=float32)>"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_he_init([10, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom layers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, initializer=None, **kwargs):\n",
    "        self.units = units\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        if not activation:\n",
    "            self.activation = my_elu()\n",
    "        else:\n",
    "            self.activation = activation\n",
    "        \n",
    "        if not initializer:\n",
    "            self.my_init = my_he_init\n",
    "        else:\n",
    "            self.my_init = initializer        \n",
    "        \n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', shape=[batch_input_shape[-1], self.units], initializer=self.my_init)\n",
    "        self.bias = self.add_weight(name='bias', shape=[self.units], initializer='zeros')\n",
    "        super().build(batch_input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return self.activation(x @ self.kernel + self.bias)\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1], [self.units])\n",
    "    \n",
    "    def get_config(self):\n",
    "        parent_configs = super().get_config()\n",
    "        return {**parent_configs, \n",
    "                \"units\": self.units,\n",
    "                \"activation\": tf.keras.activations.serialize(self.activation),\n",
    "                \"initializer\": tf.keras.initializers.serialize(self.my_init),\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[ 1.1428204 , -0.0751465 , -0.6035164 , -0.9171566 ,  1.1909186 ,\n",
       "        -0.7876803 , -0.64899766,  0.32825693,  0.8364202 ,  0.5899803 ],\n",
       "       [-0.65485215,  0.07271709,  0.86113876,  2.318538  , -0.6699641 ,\n",
       "         1.4424869 ,  0.97455406, -0.26328528, -0.54093933, -0.42257512],\n",
       "       [-0.83045304,  0.12130825,  1.4365708 ,  3.8678362 , -0.84265494,\n",
       "         2.4063885 ,  1.6257726 , -0.39934397, -0.72714984, -0.59994334],\n",
       "       [-0.8056033 ,  0.11195901,  1.3258541 ,  3.5697417 , -0.8185522 ,\n",
       "         2.220928  ,  1.5004741 , -0.37527746, -0.6984234 , -0.57067513],\n",
       "       [ 2.0640433 , -0.1315906 , -0.81191415, -0.98887575,  2.1509132 ,\n",
       "        -0.9391193 , -0.8490664 ,  0.59286356,  1.5106552 ,  1.065561  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = my_dense(units=10)\n",
    "temp(tf.random.normal(shape=(5,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[0.10680518, 0.04703631, 0.10234663, 0.09287959, 0.04294725,\n",
       "        0.11431344, 0.15661128, 0.10840799, 0.15948589, 0.06916639],\n",
       "       [0.07417963, 0.1906956 , 0.07791227, 0.08712405, 0.21174625,\n",
       "        0.06859852, 0.04774178, 0.07291834, 0.0467524 , 0.12233116],\n",
       "       [0.06541538, 0.2167421 , 0.06961959, 0.08022454, 0.24753709,\n",
       "        0.05923524, 0.03739871, 0.06400742, 0.03641813, 0.12340179],\n",
       "       [0.08537249, 0.15511   , 0.08806465, 0.09451346, 0.165729  ,\n",
       "        0.08125221, 0.06460769, 0.08445159, 0.06375772, 0.11714119],\n",
       "       [0.10568273, 0.06750244, 0.1032479 , 0.09791277, 0.06422868,\n",
       "        0.10968118, 0.13027751, 0.10654672, 0.13157924, 0.08334084]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = my_dense(units=10, activation=my_softmax, initializer=my_glorot_init)\n",
    "temp(tf.random.normal(shape=(5,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_dropout(tf.keras.layers.Layer):\n",
    "    def __init__(self, drate, **kwargs):\n",
    "        self.drate = drate\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            mask = tf.random.uniform(shape=inputs.shape) > self.drate\n",
    "            return tf.where(mask, inputs, 0) / (1 - self.drate)\n",
    "        \n",
    "        else:\n",
    "            return inputs\n",
    "        \n",
    "    def get_config(self):\n",
    "        return {**super().get_config(), \"drate\": self.drate}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "tf.Tensor(\n",
      "[-1.5063496   0.          0.39664894  0.         -0.54375064 -0.5133027\n",
      " -1.3359358   0.          0.          0.        ], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.keras.backend.learning_phase_scope(1):\n",
    "    temp = my_dropout(0.2)(tf.random.normal(shape=(10,)))\n",
    "    print (temp.shape)\n",
    "    print (temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_flatten(tf.keras.layers.Layer):\n",
    "    def call(self, x):\n",
    "        return tf.reshape(x, shape=[x.shape[0], -1])\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape([batch_input_shape[0]], [tf.reduce_prod(batch_input_shape[1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 784), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_flatten()(X_train[:10].astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_conc(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        a, b = inputs\n",
    "        return tf.concat([a, b], axis=1)\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shapes):\n",
    "        return tf.TensorShape(batch_input_shapes[0][:-1], [batch_input_shapes[0][-1] + batch_input_shapes[1][-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0.34733737, 0.50976706, 0.92616856, 0.42780864, 0.82958376],\n",
       "       [0.48532736, 0.12041569, 0.8498498 , 0.2160269 , 0.3847556 ],\n",
       "       [0.9411465 , 0.5607525 , 0.5391358 , 0.7781346 , 0.00567448],\n",
       "       [0.23165798, 0.10524464, 0.62537086, 0.6577296 , 0.26813507],\n",
       "       [0.28594744, 0.6244042 , 0.04825294, 0.8871002 , 0.33091247]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_conc()([tf.random.uniform(shape=(5, 2)), tf.random.uniform(shape=(5, 3))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done creating the layers, let's now create the model using subclass api.\n",
    "### Model creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_mnist_model(tf.keras.models.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.flatten = my_flatten()\n",
    "        self.dense1 = my_dense(units=128)\n",
    "        self.dense2 = my_dense(units=128)\n",
    "        self.conc = my_conc()\n",
    "        self.dropout = my_dropout(drate=0.2)\n",
    "        self.dense3 = my_dense(units=256)\n",
    "        self.op = my_dense(units=10, initializer=my_glorot_init, activation=my_softmax)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        flatten = self.flatten(inputs)\n",
    "        dense1 = self.dense1(flatten)\n",
    "        dense2 = self.dense2(dense1)\n",
    "        conc = self.conc([dense1, dense2])\n",
    "        dropout = self.dropout(conc)\n",
    "        dense3 = self.dense3(dropout)\n",
    "        op = self.op(dense3)\n",
    "        \n",
    "        return op              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10)\n"
     ]
    }
   ],
   "source": [
    "with tf.keras.backend.learning_phase_scope(1):\n",
    "    temp = my_mnist_model()\n",
    "    print (temp(X_train[:50].astype(np.float32)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training (Custom loop)\n",
    "Now let's get the model to train for which let's write a function that prints out the metrics during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = ' - '.join([\"{}: {:.4f}\".format(m.name, m.result()) for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print (\"\\r{}/{} - \".format(iteration, total) + metrics, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "my_model = my_mnist_model()\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "metrics = [my_scacc_metric()]\n",
    "loss_fn = my_s_cross_entropy()\n",
    "mean_loss = tf.keras.metrics.Mean(name='Loss_Mean')\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "n_steps_train = len(X_train) // batch_size\n",
    "n_steps_test = len(X_test) // batch_size\n",
    "\n",
    "X_Train = X_train.astype(np.float32)\n",
    "y_Train = y_train.reshape(-1, 1)\n",
    "\n",
    "X_Test = X_test.astype(np.float32)\n",
    "y_Test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n",
      "60000/60000 - mean: 0.2591 - my_scacc_metric: 0.9211\n",
      "9984/10000 - mean: 0.1377 - my_scacc_metric: 0.9567\n",
      "\n",
      "\n",
      "Epoch 2/20:\n",
      "60000/60000 - mean: 0.1298 - my_scacc_metric: 0.9593\n",
      "9984/10000 - mean: 0.1108 - my_scacc_metric: 0.9656\n",
      "\n",
      "\n",
      "Epoch 3/20:\n",
      "60000/60000 - mean: 0.0952 - my_scacc_metric: 0.9703\n",
      "9984/10000 - mean: 0.0959 - my_scacc_metric: 0.9704\n",
      "\n",
      "\n",
      "Epoch 4/20:\n",
      "60000/60000 - mean: 0.0810 - my_scacc_metric: 0.9745\n",
      "9984/10000 - mean: 0.0858 - my_scacc_metric: 0.9743\n",
      "\n",
      "\n",
      "Epoch 5/20:\n",
      "60000/60000 - mean: 0.0697 - my_scacc_metric: 0.9780\n",
      "9984/10000 - mean: 0.0973 - my_scacc_metric: 0.9737\n",
      "\n",
      "\n",
      "Epoch 6/20:\n",
      "60000/60000 - mean: 0.0617 - my_scacc_metric: 0.9805\n",
      "9984/10000 - mean: 0.0949 - my_scacc_metric: 0.9752\n",
      "\n",
      "\n",
      "Epoch 7/20:\n",
      "60000/60000 - mean: 0.0551 - my_scacc_metric: 0.9826\n",
      "9984/10000 - mean: 0.0998 - my_scacc_metric: 0.9722\n",
      "\n",
      "\n",
      "Epoch 8/20:\n",
      "60000/60000 - mean: 0.0476 - my_scacc_metric: 0.9852\n",
      "9984/10000 - mean: 0.0926 - my_scacc_metric: 0.9764\n",
      "\n",
      "\n",
      "Epoch 9/20:\n",
      "60000/60000 - mean: 0.0460 - my_scacc_metric: 0.9859\n",
      "9984/10000 - mean: 0.0997 - my_scacc_metric: 0.9778\n",
      "\n",
      "\n",
      "Epoch 10/20:\n",
      "60000/60000 - mean: 0.0431 - my_scacc_metric: 0.9872\n",
      "9984/10000 - mean: 0.0966 - my_scacc_metric: 0.9782\n",
      "\n",
      "\n",
      "Epoch 11/20:\n",
      "60000/60000 - mean: 0.0383 - my_scacc_metric: 0.9886\n",
      "9984/10000 - mean: 0.0966 - my_scacc_metric: 0.9794\n",
      "\n",
      "\n",
      "Epoch 12/20:\n",
      "60000/60000 - mean: 0.0407 - my_scacc_metric: 0.9878\n",
      "9984/10000 - mean: 0.0844 - my_scacc_metric: 0.9813\n",
      "\n",
      "\n",
      "Epoch 13/20:\n",
      "60000/60000 - mean: nan - my_scacc_metric: 0.3002917\n",
      "9984/10000 - mean: nan - my_scacc_metric: 0.0981\n",
      "\n",
      "\n",
      "Epoch 14/20:\n",
      "60000/60000 - mean: nan - my_scacc_metric: 0.0987\n",
      "9984/10000 - mean: nan - my_scacc_metric: 0.0981\n",
      "\n",
      "\n",
      "Epoch 15/20:\n",
      "60000/60000 - mean: nan - my_scacc_metric: 0.0987\n",
      "9984/10000 - mean: nan - my_scacc_metric: 0.0981\n",
      "\n",
      "\n",
      "Epoch 16/20:\n",
      "60000/60000 - mean: nan - my_scacc_metric: 0.0987\n",
      "9984/10000 - mean: nan - my_scacc_metric: 0.0981\n",
      "\n",
      "\n",
      "Epoch 17/20:\n",
      "60000/60000 - mean: nan - my_scacc_metric: 0.0987\n",
      "9984/10000 - mean: nan - my_scacc_metric: 0.0981\n",
      "\n",
      "\n",
      "Epoch 18/20:\n",
      "60000/60000 - mean: nan - my_scacc_metric: 0.0987\n",
      "9984/10000 - mean: nan - my_scacc_metric: 0.0981\n",
      "\n",
      "\n",
      "Epoch 19/20:\n",
      "60000/60000 - mean: nan - my_scacc_metric: 0.0987\n",
      "9984/10000 - mean: nan - my_scacc_metric: 0.0981\n",
      "\n",
      "\n",
      "Epoch 20/20:\n",
      "60000/60000 - mean: nan - my_scacc_metric: 0.0987\n",
      "9984/10000 - mean: nan - my_scacc_metric: 0.0981"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    if epoch != 1:\n",
    "        print (\"\\n\\n\")\n",
    "    print (\"Epoch {}/{}:\".format(epoch, n_epochs))\n",
    "    ids = tf.random.shuffle(tf.range(start=0, limit=len(X_train)))\n",
    "    \n",
    "    for step in range(1, n_steps_train + 1):\n",
    "        temp_ids = ids[(step-1)*batch_size: step*batch_size]\n",
    "        X_batch, y_batch = X_Train[temp_ids], y_Train[temp_ids]        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = my_model(X_batch, training=True)\n",
    "            main_loss = loss_fn(y_batch, y_pred)\n",
    "            loss = tf.add_n([main_loss] + my_model.losses)\n",
    "        gradients = tape.gradient(loss, my_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, my_model.trainable_variables))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "        \n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()\n",
    "    \n",
    "    for step in range(1, n_steps_test + 1):\n",
    "        X_batch = X_Test[(step - 1)*batch_size: step * batch_size]\n",
    "        y_batch = y_Test[(step - 1)*batch_size: step * batch_size]\n",
    "        \n",
    "        y_pred = my_model(X_batch, training=False)\n",
    "        val_loss = loss_fn(y_batch, y_pred)\n",
    "        \n",
    "        mean_loss(val_loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "            \n",
    "        print_status_bar(step * batch_size, len(y_Test), mean_loss, metrics)\n",
    "    \n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
